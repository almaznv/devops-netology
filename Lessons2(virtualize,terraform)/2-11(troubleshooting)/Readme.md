## Домашнее задание к занятию "6.6. Troubleshooting"

1. [Задание](https://github.com/netology-code/virt-homeworks/tree/master/06-db-06-troobleshooting#%D0%B7%D0%B0%D0%B4%D0%B0%D1%87%D0%B0-1)  

* для быстрого решения проблемы:

```shell
db.currentOp() # выводим список операций. Находим в ответе opid
db.killOp(<opid of the query to kill>) # убиваем запрос
```

* если такое происходит с какойто периодичностью:
  * включить профилировщик запросов длительностью выполнения более 2 секунд : db.setProfilingLevel(1, { slowms: 2000 })  
  * прочитать то что поймал профилировщик (db.system.profile.find()), отмести то что так и должно работать  
  * проанализировать запросы на предмет производительности, план запроса командой cursor.explain(), cursor.explain("executionStats") , от самого долгого запроса к менее
  * найти проблему, добавить индексов (createIndex) или переделать запрос

2. [Задание](https://github.com/netology-code/virt-homeworks/tree/master/06-db-06-troobleshooting#%D0%B7%D0%B0%D0%B4%D0%B0%D1%87%D0%B0-2)  

Рост количества записанных значений относительно истекших значит что , миханизм очистки истекших либо не очищает их, либо не успевает очищать изза например низкой производительности ноды. В какойто момент, вероятно, нода блокируется на запись т.к. заканчивается память.  

Нужно понять, почему новой реплике не хватает производительности, и посмотреть настройку ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP 

3. [Задание](https://github.com/netology-code/virt-homeworks/tree/master/06-db-06-troobleshooting#%D0%B7%D0%B0%D0%B4%D0%B0%D1%87%D0%B0-3)  

* Вероятно, с ростом количества записей в бд, скорость выполнения запросов уменьшилась, поэтому субд не укладывается в лимит времени для ответа.  
  Для временного купирования проблемы , можно увеличить net_read_timeout. Далее попрофилировать запросы, добавить индексов, поправить запросы. Потом вероятно значенеи net_read_timeout можно вернуть обратно  
  Либо может добавить ресурсов серверу,mem,cpu,положить файлы базы на ssd диск например 
* Нужно проверить устойчивость сетевого соеднинения между бекендом/клиентами и базой.
* Возможно ктото отправляет огромные блобы, больше чем настройка  max_allowed_packet. Соотвественно либо запретить клиенту так делать, либо увеличить  max_allowed_packet.


4. [Задание](https://github.com/netology-code/virt-homeworks/tree/master/06-db-06-troobleshooting#%D0%B7%D0%B0%D0%B4%D0%B0%D1%87%D0%B0-4)  

Серверу не хватает памяти. OOM killer process убивает процесс postgres чтоб вм оставалсь доступной.

* установить лимит используемой памяти на вм, просчитав достаточные значения (shared_buffers + (temp_buffers + work_mem) * max_connections). Добавить памяти например 30% сверх рассчитанного.
* снизить вероятность убийства процесса установкой overcommit_memory = 2 (ядро не будет резервировать больше памяти, чем указано в параметре overcommit_ratio)
* попрофилировать запросы, найти тяжелые, добавить индексов, попросить разрабов переделать запросы.
